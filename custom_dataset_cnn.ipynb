{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "916461cf-323f-4c4b-b4eb-f56d9516b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from keras.utils import load_img, img_to_array, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354f127a-ee98-45c1-907e-e5b0f71960ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_base_path = r'/Users/praneethkumarpalepu/Downloads/animals/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db37103-712d-4413-b8ab-d187baa8ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_dataset_loader(base_path, image_size=(224, 224), test_size=0.2, random_state=0, batch_size= 64):\n",
    "    images, labels = [], []\n",
    "    image_file_location, act_label = [], []\n",
    "    for folder in os.listdir(base_path):\n",
    "        if not folder.startswith('.'):\n",
    "            folder_path = os.path.join(base_path, folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                _, ext = os.path.splitext(file)\n",
    "                if ext.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    image_file_location.append(file_path)\n",
    "                    act_label.append(folder)\n",
    "\n",
    "    total_files = len(image_file_location)\n",
    "    quotient = total_files//batch_size\n",
    "    reminder = total_files % batch_size\n",
    "    total_batches = quotient+1 if reminder > 0 else quotient\n",
    "\n",
    "    for batch in tqdm(range(total_batches)):\n",
    "        start_index = batch * batch_size\n",
    "        end_index = (batch * batch_size)+batch_size\n",
    "        if end_index > total_files:\n",
    "            end_index = end_index - total_files\n",
    "        image_batch = image_file_location[start_index:end_index]\n",
    "        label = act_label[start_index:end_index]\n",
    "        counter= 0\n",
    "        tmp_image, tmp_labels = [], []\n",
    "        for file in image_batch:           \n",
    "            image = load_img(file, target_size=image_size)\n",
    "            image_arr = img_to_array(image)\n",
    "            tmp_image.append(image_arr)\n",
    "            tmp_labels.append(label[counter])\n",
    "            counter+=1\n",
    "\n",
    "        images.extend(np.array(tmp_image))\n",
    "        labels.extend(np.array(tmp_labels))\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    xtr, xte, ytr, yte = train_test_split(images, labels, test_size= test_size, random_state= random_state)\n",
    "\n",
    "    return (xtr, ytr), (xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bc20ff5-b261-4ada-a77b-042ddce66a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [00:04<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "(xtr, ytr), (xte, yte) = image_dataset_loader(images_base_path, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea2922b4-3331-42c4-8945-5552589bc1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2355, 224, 224, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e9f9e9-a2c6-4af3-82ce-1127721b8e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 224, 224, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f2a543c-8c33-4212-8625-31ec33ac7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0ebcb53-f73a-46a8-8a3e-7596bfb403ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = encoder.fit_transform(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0637a619-15d8-461f-9a6c-d5c0998cc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yte = encoder.transform(yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af923a24-3b5c-4070-8f3d-41b7ef817768",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = to_categorical(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cf772ef-4284-4692-91f7-f107891d4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yte = to_categorical(yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ad22e22-6706-4777-855a-d2f1bae3e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = xtr.astype('float32')/255\n",
    "xte = xte.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "967ddd5e-fe31-47dd-8a16-000fa8c0dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83658104-fdd2-478c-9669-516b6bb503e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ca19c20-b735-44cb-99f9-770a08d17d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.3519 - loss: 1.0910 - val_accuracy: 0.4652 - val_loss: 1.0140\n",
      "Epoch 2/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.5453 - loss: 0.9486 - val_accuracy: 0.5637 - val_loss: 0.8187\n",
      "Epoch 3/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5654 - loss: 0.7872 - val_accuracy: 0.4941 - val_loss: 0.9227\n",
      "Epoch 4/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.5423 - loss: 0.8370 - val_accuracy: 0.5840 - val_loss: 0.8325\n",
      "Epoch 5/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.5741 - loss: 0.7734 - val_accuracy: 0.5365 - val_loss: 0.7909\n",
      "Epoch 6/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.5896 - loss: 0.7546 - val_accuracy: 0.5993 - val_loss: 0.7691\n",
      "Epoch 7/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6s/step - accuracy: 0.6240 - loss: 0.7086 - val_accuracy: 0.6146 - val_loss: 0.7349\n",
      "Epoch 8/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - accuracy: 0.6470 - loss: 0.6618 - val_accuracy: 0.6486 - val_loss: 0.6892\n",
      "Epoch 9/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6s/step - accuracy: 0.6635 - loss: 0.6441 - val_accuracy: 0.6876 - val_loss: 0.6569\n",
      "Epoch 10/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6s/step - accuracy: 0.6638 - loss: 0.6203 - val_accuracy: 0.6452 - val_loss: 0.7165\n",
      "Epoch 11/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 6s/step - accuracy: 0.6799 - loss: 0.6164 - val_accuracy: 0.6655 - val_loss: 0.7122\n",
      "Epoch 12/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.6927 - loss: 0.6229 - val_accuracy: 0.7097 - val_loss: 0.6295\n",
      "Epoch 13/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7s/step - accuracy: 0.7355 - loss: 0.5466 - val_accuracy: 0.6893 - val_loss: 0.6372\n",
      "Epoch 14/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7s/step - accuracy: 0.7352 - loss: 0.5208 - val_accuracy: 0.7250 - val_loss: 0.6180\n",
      "Epoch 15/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6s/step - accuracy: 0.7953 - loss: 0.4612 - val_accuracy: 0.6995 - val_loss: 0.6736\n",
      "Epoch 16/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6s/step - accuracy: 0.7903 - loss: 0.4459 - val_accuracy: 0.6876 - val_loss: 0.6689\n",
      "Epoch 17/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - accuracy: 0.7916 - loss: 0.4458 - val_accuracy: 0.7131 - val_loss: 0.6381\n",
      "Epoch 18/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6s/step - accuracy: 0.8074 - loss: 0.4254 - val_accuracy: 0.7334 - val_loss: 0.6131\n",
      "Epoch 19/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.8299 - loss: 0.3779 - val_accuracy: 0.7351 - val_loss: 0.6050\n",
      "Epoch 20/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.8355 - loss: 0.3740 - val_accuracy: 0.7250 - val_loss: 0.6394\n",
      "Epoch 21/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5s/step - accuracy: 0.8443 - loss: 0.3444 - val_accuracy: 0.7368 - val_loss: 0.6727\n",
      "Epoch 22/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - accuracy: 0.8857 - loss: 0.2785 - val_accuracy: 0.7148 - val_loss: 0.7159\n",
      "Epoch 23/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - accuracy: 0.8985 - loss: 0.2599 - val_accuracy: 0.7368 - val_loss: 0.7838\n",
      "Epoch 24/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.9049 - loss: 0.2461 - val_accuracy: 0.7233 - val_loss: 0.7634\n",
      "Epoch 25/25\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.8984 - loss: 0.2681 - val_accuracy: 0.7114 - val_loss: 0.7832\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtr, ytr, validation_data=(xte, yte), epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3861c5-7cab-4d92-8ad7-6c655c42f115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classes",
   "language": "python",
   "name": "classes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
